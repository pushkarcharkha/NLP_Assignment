{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e189c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"I am a third year engineering student\",\n",
    "    \"I am learning natural language processing\",\n",
    "    \"Natural language processing is interesting\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9fdf8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "['am' 'engineering' 'interesting' 'is' 'language' 'learning' 'natural'\n",
      " 'processing' 'student' 'third' 'year']\n",
      "\n",
      "Count Occurrence Matrix:\n",
      "[[1 1 0 0 0 0 0 0 1 1 1]\n",
      " [1 0 0 0 1 1 1 1 0 0 0]\n",
      " [0 0 1 1 1 0 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "bow_counts = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(\"Vocabulary:\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nCount Occurrence Matrix:\")\n",
    "print(bow_counts.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af2ddbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalized Count Occurrence Matrix:\n",
      "[[0.2 0.2 0.  0.  0.  0.  0.  0.  0.2 0.2 0.2]\n",
      " [0.2 0.  0.  0.  0.2 0.2 0.2 0.2 0.  0.  0. ]\n",
      " [0.  0.  0.2 0.2 0.2 0.  0.2 0.2 0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer_norm = TfidfVectorizer(use_idf=False, norm='l1')\n",
    "bow_normalized = vectorizer_norm.fit_transform(documents)\n",
    "\n",
    "print(\"\\nNormalized Count Occurrence Matrix:\")\n",
    "print(bow_normalized.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97bb46ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Vocabulary:\n",
      "['am' 'engineering' 'interesting' 'is' 'language' 'learning' 'natural'\n",
      " 'processing' 'student' 'third' 'year']\n",
      "\n",
      "TF-IDF Matrix:\n",
      "[[0.35543247 0.46735098 0.         0.         0.         0.\n",
      "  0.         0.         0.46735098 0.46735098 0.46735098]\n",
      " [0.41779577 0.         0.         0.         0.41779577 0.54935123\n",
      "  0.41779577 0.41779577 0.         0.         0.        ]\n",
      " [0.         0.         0.51741994 0.51741994 0.3935112  0.\n",
      "  0.3935112  0.3935112  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(documents)\n",
    "\n",
    "print(\"\\nTF-IDF Vocabulary:\")\n",
    "print(tfidf.get_feature_names_out())\n",
    "\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5caa0575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pushk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\pushk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8859bfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'am', 'a', 'third', 'year', 'engineering', 'student'], ['i', 'am', 'learning', 'natural', 'language', 'processing'], ['natural', 'language', 'processing', 'is', 'interesting']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_docs = [word_tokenize(doc.lower()) for doc in documents]\n",
    "print(tokenized_docs)\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences=tokenized_docs,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38de69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word2Vec Embedding for 'language':\n",
      "[-8.6186444e-03  3.6655073e-03  5.1910528e-03  5.7405424e-03\n",
      "  7.4657369e-03 -6.1686523e-03  1.1050246e-03  6.0480167e-03\n",
      " -2.8406116e-03 -6.1747469e-03 -4.0898522e-04 -8.3694998e-03\n",
      " -5.5987458e-03  7.1038185e-03  3.3531163e-03  7.2263936e-03\n",
      "  6.8005994e-03  7.5303270e-03 -3.7887350e-03 -5.6302088e-04\n",
      "  2.3479695e-03 -4.5194137e-03  8.3897980e-03 -9.8586734e-03\n",
      "  6.7636697e-03  2.9150555e-03 -4.9329014e-03  4.3976582e-03\n",
      " -1.7385620e-03  6.7119543e-03  9.9642761e-03 -4.3623298e-03\n",
      " -5.9799233e-04 -5.6944964e-03  3.8517585e-03  2.7873137e-03\n",
      "  6.8914271e-03  6.1008246e-03  9.5375590e-03  9.2733726e-03\n",
      "  7.8978380e-03 -6.9895885e-03 -9.1567868e-03 -3.5465878e-04\n",
      " -3.1008108e-03  7.8932513e-03  5.9381686e-03 -1.5458858e-03\n",
      "  1.5098398e-03  1.7901435e-03  7.8167869e-03 -9.5103746e-03\n",
      " -2.0661489e-04  3.4694851e-03 -9.3849056e-04  8.3817681e-03\n",
      "  9.0099815e-03  6.5362528e-03 -7.1057846e-04  7.7109542e-03\n",
      " -8.5356412e-03  3.2066044e-03 -4.6376507e-03 -5.0886404e-03\n",
      "  3.5882257e-03  5.3710118e-03  7.7682403e-03 -5.7675932e-03\n",
      "  7.4338736e-03  6.6249855e-03 -3.7092757e-03 -8.7443329e-03\n",
      "  5.4369415e-03  6.5111271e-03 -7.8729843e-04 -6.7084068e-03\n",
      " -7.0850858e-03 -2.4984065e-03  5.1427637e-03 -3.6642766e-03\n",
      " -9.3692355e-03  3.8280208e-03  4.8854984e-03 -6.4273807e-03\n",
      "  1.2071127e-03 -2.0742444e-03  2.3663162e-05 -9.8829921e-03\n",
      "  2.6928957e-03 -4.7494601e-03  1.0887519e-03 -1.5760042e-03\n",
      "  2.1964870e-03 -7.8807278e-03 -2.7180137e-03  2.6632042e-03\n",
      "  5.3480733e-03 -2.3923214e-03 -9.5095327e-03  4.5046848e-03]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nWord2Vec Embedding for 'language':\")\n",
    "print(model.wv['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9438705b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
